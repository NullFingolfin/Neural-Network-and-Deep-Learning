{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c936ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cart import TreeNode, BinaryDecisionTree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import cat_label_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c72caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost定义\n",
    "class XGBoost:\n",
    "    def __init__(self, n_estimators=300, learning_rate=0.001, \n",
    "                 min_samples_split=2,\n",
    "                 min_gini_impurity=999, \n",
    "                 max_depth=2):\n",
    "        # 树的棵树\n",
    "        self.n_estimators = n_estimators\n",
    "        # 学习率\n",
    "        self.learning_rate = learning_rate \n",
    "        # 结点分裂最小样本数\n",
    "        self.min_samples_split = min_samples_split \n",
    "        # 结点最小基尼不纯度\n",
    "        self.min_gini_impurity = min_gini_impurity  \n",
    "        # 树最大深度\n",
    "        self.max_depth = max_depth                  \n",
    "        # 用于分类的对数损失\n",
    "        # 回归任务可定义平方损失 \n",
    "        # self.loss = SquaresLoss()\n",
    "        self.loss = LogisticLoss()\n",
    "        # 初始化分类树列表\n",
    "        self.trees = []\n",
    "        # 遍历构造每一棵决策树\n",
    "        for _ in range(n_estimators):\n",
    "            tree = XGBoost_Single_Tree(\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    min_gini_impurity=self.min_gini_impurity,\n",
    "                    max_depth=self.max_depth,\n",
    "                    loss=self.loss)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    # xgboost拟合方法\n",
    "    def fit(self, X, y):\n",
    "        y = cat_label_convert(y) #标签转化为 0 1\n",
    "        y_pred = np.zeros(np.shape(y))\n",
    "        # 拟合每一棵树后进行结果累加\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = self.trees[i]\n",
    "            y_true_pred = np.concatenate((y, y_pred), axis=1)\n",
    "            tree.fit(X, y_true_pred)\n",
    "            iter_pred = tree.predict(X)\n",
    "            y_pred -= np.multiply(self.learning_rate, iter_pred)\n",
    "\n",
    "    # xgboost预测方法\n",
    "    def predict(self, X):\n",
    "        y_pred = None\n",
    "        # 遍历预测\n",
    "        for tree in self.trees:\n",
    "            iter_pred = tree.predict(X)\n",
    "            if y_pred is None:\n",
    "                y_pred = np.zeros_like(iter_pred)\n",
    "            y_pred -= np.multiply(self.learning_rate, iter_pred)\n",
    "        y_pred = np.exp(y_pred) / np.sum(np.exp(y_pred), axis=1, keepdims=True)\n",
    "        # 将概率预测转换为标签\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ceb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 分类损失函数定义\n",
    "# 定义Sigmoid类\n",
    "class Sigmoid:\n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def gradient(self, x):\n",
    "        return self.__call__(x) * (1 - self.__call__(x))\n",
    "\n",
    "# 定义Logit损失\n",
    "class LogisticLoss:\n",
    "    def __init__(self):\n",
    "        sigmoid = Sigmoid()\n",
    "        self._func = sigmoid\n",
    "        self._grad = sigmoid.gradient\n",
    "    \n",
    "    # 定义损失函数形式\n",
    "    def loss(self, y, y_pred):\n",
    "        y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15) #裁剪y_pred的值 在1e-15 ～ 1-1e-15之间\n",
    "        p = self._func(y_pred)\n",
    "        return y * np.log(p) + (1 - y) * np.log(1 - p)\n",
    "\n",
    "    # 定义一阶梯度\n",
    "    def gradient(self, y, y_pred):\n",
    "        p = self._func(y_pred)\n",
    "        return -(y - p)\n",
    "\n",
    "    # 定义二阶梯度\n",
    "    def hess(self, y, y_pred):\n",
    "        p = self._func(y_pred)\n",
    "        return p * (1 - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8facce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### XGBoost单棵树类\n",
    "class XGBoost_Single_Tree(BinaryDecisionTree):\n",
    "    # 结点分裂方法\n",
    "    def node_split(self, y):\n",
    "        # 中间特征所在列\n",
    "        feature = int(np.shape(y)[1]/2)\n",
    "        # 左子树为真实值，右子树为预测值\n",
    "        y_true, y_pred = y[:, :feature], y[:, feature:]\n",
    "        return y_true, y_pred\n",
    "\n",
    "    # 信息增益计算方法\n",
    "    def gain(self, y, y_pred):\n",
    "        # 梯度计算\n",
    "        Gradient = np.power((y * self.loss.gradient(y, y_pred)).sum(), 2)\n",
    "        # Hessian矩阵计算\n",
    "        Hessian = self.loss.hess(y, y_pred).sum()\n",
    "        return 0.5 * (Gradient / Hessian)\n",
    "\n",
    "    # 树分裂增益计算\n",
    "    # 式(12.28)\n",
    "    def gain_xgb(self, y, y1, y2):\n",
    "        # 结点分裂\n",
    "        y_true, y_pred = self.node_split(y)\n",
    "        y1, y1_pred = self.node_split(y1)\n",
    "        y2, y2_pred = self.node_split(y2)\n",
    "        true_gain = self.gain(y1, y1_pred)\n",
    "        false_gain = self.gain(y2, y2_pred)\n",
    "        gain = self.gain(y_true, y_pred)\n",
    "        return true_gain + false_gain - gain\n",
    "\n",
    "    # 计算叶子结点最优权重\n",
    "    def leaf_weight(self, y):\n",
    "        y_true, y_pred = self.node_split(y)\n",
    "        # 梯度计算\n",
    "        gradient = np.sum(y_true * self.loss.gradient(y_true, y_pred), axis=0)\n",
    "        # hessian矩阵计算\n",
    "        hessian = np.sum(self.loss.hess(y_true, y_pred), axis=0)\n",
    "        # 叶子结点得分\n",
    "        leaf_weight =  gradient / hessian\n",
    "        return leaf_weight\n",
    "\n",
    "    # 树拟合方法\n",
    "    def fit(self, X, y):\n",
    "        self.impurity_calculation = self.gain_xgb\n",
    "        self._leaf_value_calculation = self.leaf_weight\n",
    "        super(XGBoost_Single_Tree, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba5fbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heshuaichen/numpy/机器学习—公式推导与代码实现/10—16Ensemble_Learning_监督集成/utils.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([X_left, X_right])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "# 导入鸢尾花数据集\n",
    "data = datasets.load_iris()\n",
    "# 获取输入输出\n",
    "X, y = data.data, data.target\n",
    "# 数据集划分\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)  \n",
    "# 创建xgboost分类器\n",
    "clf = XGBoost()\n",
    "# 模型拟合\n",
    "clf.fit(X_train, y_train)\n",
    "# 模型预测\n",
    "y_pred = clf.predict(X_test)\n",
    "# 准确率评估\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7001270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heshuaichen/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:05] WARNING: /var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_eek2t0c4ro/croots/recipe/xgboost-split_1659548960591/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.9666666666666667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdX0lEQVR4nO3df5yVdZ338dcbRGVBRRixAZxGgkgRNFOLzaXREX9h0N6ZP7IcNHK9TU1XzWnbFO+2dVQs290elovd95SGSepA2mKT7qRrqA2KormE5SQ/RhAQlQm4Z/Czf5wLPPMLDjpnzhmu9/PxmAfX9b1+fc5HH+85872uOaOIwMzM9nz9Cl2AmZn1Dge+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfrANJ/yBpTqHrMOtp8nP41pMkNQEHA9uyhj8cEavf5zlnRsSv3191fY+kWcCYiPhCoWuxvs/v8C0fPh0Rg7O+3nPY9wRJexXy+u9VX63bipcD33qFpAMk3SmpWdIqSf8kqX+y7UOSHpW0XtI6SXdLGpJs+wlQBvxC0iZJX5NUIWllh/M3STopWZ4l6eeS7pL0FjBjZ9fvotZZku5KlsslhaQLJK2Q9IakiyUdK+l5SRsl/VvWsTMkPSHpXyW9Kem/JVVmbR8haYGkDZJelvTlDtfNrvti4B+As5PX/lyy3wWSXpL0tqQ/Sfq7rHNUSFop6SpJa5PXe0HW9oGSbpX056S+/5I0MNn2CUm/TV7Tc5Iq3sN/aitiDnzrLbVAGzAG+ChwMjAz2SbgRmAEcBhwCDALICK+CLzKuz813Jzj9aYDPweGAHfv4vq5+DgwFjgbuA34BnASMB44S9KnOuz7J6AEuB64X9LQZNtcYGXyWs8E/jn7G0KHuu8E/hn4WfLaj0z2WQucAewPXAB8V9LRWef4AHAAMBL4EvB9SQcm22YDHwP+GhgKfA14R9JI4CHgn5Lxq4H7JB20Gz2yIufAt3yoS94lbpRUJ+lg4DTgiohoiYi1wHeBcwAi4uWIqI+IrRHxOvAd4FPdnz4niyKiLiLeIROM3V4/R9+KiC0R8SugBZgbEWsjYhXwOJlvItutBW6LiNaI+BmwDJgq6RDgeODa5FxLgDnAF7uqOyI2d1VIRDwUEX+MjN8AvwL+JmuXVuD/JNf/JbAJGCepH3Ah8NWIWBUR2yLitxGxFfgC8MuI+GVy7XqgETh9N3pkRc5zhJYPn8m+wSrpOGAA0Cxp+3A/YEWyfTjwL2RCa79k2xvvs4YVWcsf3Nn1c7Qma3lzF+uDs9ZXRfunIf5M5h39CGBDRLzdYdsx3dTdJUmnkfnJ4cNkXsdfAUuzdlkfEW1Z639J6isB9gX+2MVpPwh8TtKns8YGAP+5q3qs73DgW29YAWwFSjoE0XY3AgFMjIj1kj4D/FvW9o6PkrWQCTkAkrn4jlMP2cfs6vo9baQkZYV+GbAAWA0MlbRfVuiXAauyju34WtutS9oHuA84H5gfEa2S6shMi+3KOmAL8CHguQ7bVgA/iYgvdzrK9hie0rG8i4hmMtMOt0raX1K/5Ebt9mmb/chMO2xM5pKv6XCKNcDorPU/APtKmippAPCPwD7v4/o9bThwuaQBkj5H5r7ELyNiBfBb4EZJ+0qaSGaO/e6dnGsNUJ5MxwDsTea1vg60Je/2T86lqGR660fAd5Kbx/0lTUq+idwFfFrSKcn4vskN4FG7//KtWDnwrbecTyasfk9muubnQGmy7QbgaOBNMjcO7+9w7I3APyb3BK6OiDeBS8jMf68i845/JTu3s+v3tKfI3OBdB3wbODMi1ifbzgXKybzbfwC4Ppkv78685N/1kp5JfjK4HLiXzOv4PJmfHnJ1NZnpn98BG4CbgH7JN6PpZJ4Kep3MO/5rcEbsUfyLV2Y9SNIMMr8kdnyhazHryN+9zcxSwoFvZpYSntIxM0sJv8M3M0uJon0Of8iQITFmzJhCl1H0WlpaGDRoUKHL6BPcq9y4T7kp1j4tXrx4XUR0+ZEYRRv4Bx98MI2NjYUuo+g1NDRQUVFR6DL6BPcqN+5Tboq1T5L+3N02T+mYmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZinhwDczSwkHvplZSjjwzcxSwoFvZpYSDnwzs5Rw4JuZpYQD38wsJRz4ZmYp4cA3M0sJB76ZWUo48M3MUsKBb2aWEg58M7OUcOCbmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZinhwDczSwkHvplZSigiCl1Dl8pGj4l+Z32v0GUUvasmtHHr0r0KXUaf4F7lxn3Kza761FQztRereZekxRFxTFfb/A7fzCzPtm3bxkc/+lHOOOMMAObNm8f48ePp168fjY2N7fa98cYbGTNmDOPGjePhhx/u8nwbNmxgypQpjB07lilTpvDGG2/kVEfeAl/S5ZJekhSSnk++fivpyHxd08ysGH3ve9/jsMMO27F+xBFHcP/99zN58uR2+/3+97/nnnvu4cUXX2ThwoVccsklbNu2rdP5ampqqKysZPny5VRWVlJTU5NTHfl8h38JcDrwSeBTETER+BZwRx6vaWZWVFauXMlDDz3EzJkzd4wddthhjBs3rtO+8+fP55xzzmGfffbh0EMPZcyYMTz99NNd7ldVVQVAVVUVdXV1OdWSl8CX9ANgNLAA+HhEbP9540lgVD6uaWZWjK644gpuvvlm+vXbddyuWrWKQw45ZMf6qFGjWLVqVaf91qxZQ2lpKQClpaWsXbs2p1rycmcmIi6WdCpwQkSsy9r0JeA/ujtO0kXARQAlJQdx3YS2fJS3Rzl4YObmke2ae5Ub9yk3u+pTQ0MDixYtorW1lbfffpslS5awfv16GhoaduyzceNGFi9ezKZNm4DMTwMvvfTSjn2am5t58cUXKSkpaXfutra2dufpuN6dXrsVL+kEMoF/fHf7RMQdJFM+ZaPHhJ8U2DU/UZE79yo37lNudvmUznkVPPzwwyxevJgZM2awZcsW3nrrLebMmcNdd90FwJAhQ/jYxz7GMcdkHqpZtGgRABUVFUDmBu7JJ5/MpEmT2p175MiRjBs3jtLSUpqbmxkxYsSOY3amV57SkTQRmANMj4j1vXFNM7NCu/HGG1m5ciVNTU3cc889nHjiiTvCvivTpk3jnnvuYevWrbzyyissX76c4447rsv9amtrAaitrWX69Ok51ZP3wJdUBtwPfDEi/pDv65mZFbsHHniAUaNGsWjRIqZOncopp5wCwPjx4znrrLM4/PDDOfXUU/n+979P//79AZg5c+aORzirq6upr69n7Nix1NfXU11dndN18/aLV5KagGOAGuCzwJ+TTW3d/VJAtnHjxsWyZcvyUtuepKGhIacf5cy9ypX7lJti7dPOfvEqbxN1EVGeLM5MvszMrID8m7ZmZinhwDczSwkHvplZSjjwzcxSwoFvZpYSDnwzs5Rw4JuZpYQD38wsJRz4ZmYp4cA3M0sJB76ZWUo48M3MUsKBb2aWEg58M7OUcOCbmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZinhwDczSwkHvplZSjjwzcxSwoFvZpYSDnwzs5Rw4JuZpYQD38wsJRz4ZmYpsVehC+jO5tZtlFc/VOgyit5VE9qY4T7lxL3KTTH0qalmKlu2bGHy5Mls3bqVtrY2zjzzTG644YYd+8yePZtrrrmG119/nZKSkh3jr776KocffjizZs3i6quv7nTuDRs2cPbZZ9PU1ER5eTn33nsvBx54YK+8rkLL2zt8SZdLeknSG5Kel7REUqOk4/N1TTPbc+yzzz48+uijPPfccyxZsoSFCxfy5JNPArBixQrq6+spKyvrdNyVV17Jaaed1u15a2pqqKysZPny5VRWVlJTU5O311Bs8jmlcwlwOnAIcGREHAVcCMzJ4zXNbA8hicGDBwPQ2tpKa2srkoBMqN9888071rerq6tj9OjRjB8/vtvzzp8/n6qqKgCqqqqoq6vLzwsoQnkJfEk/AEYDC4AvR0QkmwYB0e2BZmZZtm3bxlFHHcXw4cOZMmUKH//4x1mwYAEjR47kyCOPbLdvS0sLN910E9dff/1Oz7lmzRpKS0sBKC0tZe3atXmrv9jkZQ4/Ii6WdCpwQkSsk/S3wI3AcGBqd8dJugi4CKCk5CCum9CWj/L2KAcPzMy52q65V7kphj41NDTsWL7tttvYtGkT3/zmN/nwhz/M7NmzueWWW2hoaGDLli088cQTHHDAAdx+++2cfPLJNDY20tTUxMCBA9udZ7u2trZ24x3Xc7Vp06b3dFwh9cpN24h4AHhA0mTgW8BJ3ex3B3AHQNnoMXHr0qK9p1w0rprQhvuUG/cqN8XQp6bzKjqNLV68mNWrV7N+/XouvfRSANatW8dll13G008/zerVq3nqqaeora1l48aN9OvXj/Hjx+/Yd7uRI0cybtw4SktLaW5uZsSIEVRUdL7erjQ0NLyn4wqpV/+rRsRjkj4kqSQi1vXmtc2sb3n99dcZMGAAQ4YMYfPmzfz617/m2muvbTcFU15eTmNjIyUlJTz++OM7xmfNmsXgwYM7hT3AtGnTqK2tpbq6mtraWqZPn94rr6cY5DSHn4T0PslyRfIEzpAcjx2j5M6KpKOBvYH177FeM0uJ5uZmTjjhBCZOnMixxx7LlClTOOOMM97TuWbOnEljYyMA1dXV1NfXM3bsWOrr66muru7Jsotaru/w7wOOkTQGuJPMzdifknkKZ1c+C5wvqRXYDJyddRPXzKxLEydO5Nlnn93pPk1NTV2Oz5o1q936nDnvPhw4bNgwHnnkkfdbXp+Ua+C/ExFtyc3X2yLiXyXt9L9ERJQnizclX7tl4ID+LKvp9v6uJRoaGrqc77TO3KvcuE97rlwfy2yVdC5QBTyYjA3IT0lmZpYPuQb+BcAk4NsR8YqkQ4G78leWmZn1tJymdCLi95KuBcqS9VeA9Pw+spnZHiDXp3Q+DSwBFibrR0lakMe6zMysh+U6pTMLOA7YCBARS4BD81KRmZnlRa6B3xYRb3YY86OVZmZ9SK6PZb4g6fNAf0ljgcuB3+avLDMz62m5vsO/DBgPbCXzC1dvAlfkqSYzM8uDXb7Dl9QfWBARJwHfyH9JZmaWD7t8hx8R24C/SDqgF+oxM7M8yXUOfwuwVFI90LJ9MCIuz0tVZmbW43IN/IeSLzMz66Ny/U3b2nwXYmZm+ZVT4Et6hS6eu4+I0T1ekZmZ5UWuUzrHZC3vC3wOGNrz5ZiZWb7k9Bx+RKzP+loVEbcBJ+a3NDMz60m5TukcnbXaj8w7/v3yUpGZmeVFrlM6t2YttwGvAGf1fDlmZpYvuQb+lyLiT9kDyR9BMTOzPiLXz9L5eY5jZmZWpHb6Dl/SR8h8aNoBkv5X1qb9yTytY2ZmfcSupnTGAWcAQ4BPZ42/DXw5TzWZmVke7DTwI2I+MF/SpIhY1Es1mZlZHuR60/ZZSV8hM72zYyonIi7MS1VmZtbjcr1p+xPgA8ApwG+AUWSmdczMrI/INfDHRMQ3gZbkg9SmAhPyV5aZmfW0XAO/Nfl3o6QjgAOA8rxUZGZmeZHrHP4dkg4EvgksAAYD1+WtKjMz63G5fh7+nGTxN4A/EtnMrA/KaUpH0sGS7pT0H8n64ZK+lN/SzMysJ+U6h///gIeBEcn6H4Ar8lCPmZnlSa6BXxIR9wLvAEREG7Atb1WZmVmPyzXwWyQNI/kzh5I+AbyZt6rMzKzH5fqUzt+TeTrnQ5KeAA4CzsxbVcDm1m2UVz+Uz0vsEa6a0MaMAvepqWZqQa9vZrnZ6Tt8SWUAEfEM8Cngr4G/A8ZHxPP5L8/6kgsvvJDhw4dzxBFHdNo2e/ZsJLFu3bp246+++iqDBw9m9uzZXZ5zw4YNTJkyhbFjxzJlyhTeeOONvNRulga7mtKpy1r+WUS8GBEvRERrdwdsJ+lySS9JulvSv0h6WdLzHf5cou1BZsyYwcKFCzuNr1ixgvr6esrKyjptu/LKKznttNO6PWdNTQ2VlZUsX76cyspKampqerRmszTZVeAra3l3n7+/BDgduBsYm3xdBNy+m+exPmLy5MkMHTq00/iVV17JzTffjKR243V1dYwePZrx48d3e8758+dTVVUFQFVVFXV1dT1as1ma7Crwo5vlnZL0AzLfIBYADwA/jowngSGSSne7UuuTFixYwMiRIznyyCPbjbe0tHDTTTdx/fXX7/T4NWvWUFqa+d+ltLSUtWvX5q1Wsz3drm7aHinpLTLv9AcmyyTrERH7d3VQRFws6VTgBDLP8K/I2rwSGAk0dzxO0kVkfgqgpOQgrpvQthsvJZ0OHpi5cVtIDQ0NO5Zfe+01WlpaaGhoYMuWLVx77bXccsstO9afeOIJDjjgAG6//XZOPvlkGhsbaWpqYuDAge3Os11bW1u78Y7ru2PTpk3v+dg0cZ9y0xf7tKs/gNK/B66hLsa6/GkhIu4A7gAoGz0mbl2a60NE6XXVhDYK3aem8yreXW5qYtCgQVRUVLB06VLWr1/PpZdeCsC6deu47LLLePrpp1m9ejVPPfUUtbW1bNy4kX79+jF+/Pgd+243cuRIxo0bR2lpKc3NzYwYMYKKigrei4aGhvd8bJq4T7npi33qjaRYCRyStT4KWN0L17UCmzBhQrspmPLychobGykpKeHxxx/fMT5r1iwGDx7cKewBpk2bRm1tLdXV1dTW1jJ9+vReqd1sT5TrL169HwuA85XxCeDNiOg0nWN937nnnsukSZNYtmwZo0aN4s4773xP55k5cyaNjY0AVFdXU19fz9ixY6mvr6e6uronSzZLld54h/9LMk/rvAz8Bbggl4MGDujPMv9Czy41NDS0m1IppLlz5+50e1NTU5fjs2bNarc+Z86cHcvDhg3jkUceeb+lmRl5DPyIKM9a/Uq+rmNmZrnpjSkdMzMrAg58M7OUcOCbmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZinhwDczSwkHvplZSjjwzcxSwoFvZpYSDnwzs5Rw4JuZpYQD38wsJRz4ZmYp4cA3M0sJB76ZWUo48M3MUsKBb2aWEg58M7OUcOCbmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhJ7FbqA7mxu3UZ59UOFLqPoXTWhjRld9KmpZioAF154IQ8++CDDhw/nhRdeAGDDhg2cffbZNDU1UV5ezr333suBBx5Ia2srM2fO5JlnnqGtrY3zzz+fr3/9653O3d3xZlbc8vYOX9Llkl6SdJ+kRZK2Sro6X9ezrs2YMYOFCxe2G6upqaGyspLly5dTWVlJTU0NAPPmzWPr1q0sXbqUxYsX88Mf/pCmpqZO5+zueDMrbvmc0rkEOB3438DlwOw8Xsu6MXnyZIYOHdpubP78+VRVVQFQVVVFXV0dAJJoaWmhra2NzZs3s/fee7P//vt3Omd3x5tZcctL4Ev6ATAaWACcFxG/A1rzcS3bfWvWrKG0tBSA0tJS1q5dC8CZZ57JoEGDKC0tpaysjKuvvrrTN4udHW9mxS0vc/gRcbGkU4ETImJdrsdJugi4CKCk5CCum9CWj/L2KAcPzMzjd9TQ0LBj+bXXXqOlpWXHWFtbW7vt29eXLl3KunXrmDt3Lm+//TZf/epXGTx4MCNGjGh37u6OL3abNm3qE3UWmvuUm77Yp6K6aRsRdwB3AJSNHhO3Li2q8orSVRPa6KpPTedVvLvc1MSgQYOoqMiMjRw5knHjxlFaWkpzczMjRoygoqKCefPmUVVVxUknnQTAL37xC/baa68dx23X3fHFrqGhoU/UWWjuU276Yp/8WGYKTZs2jdraWgBqa2uZPn06AGVlZTz66KNEBC0tLTz55JN85CMfyfl4MytuDvw93LnnnsukSZNYtmwZo0aN4s4776S6upr6+nrGjh1LfX091dXVAHzlK19h06ZNHHHEERx77LFccMEFTJw4EYCZM2fS2NgI0O3xZlbc8j5nIukDQCOwP/COpCuAwyPirXxf22Du3Lldjj/yyCOdxgYPHsy8efO63H/OnDk7locNG9bl8WZW3PIW+BFRnrU6anePHzigP8uSXx6y7jU0NLSbrzcz646ndMzMUsKBb2aWEg58M7OUcOCbmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZinhwDczSwkHvplZSjjwzcxSwoFvZpYSDnwzs5Rw4JuZpYQD38wsJRz4ZmYp4cA3M0sJB76ZWUo48M3MUsKBb2aWEg58M7OUcOCbmaWEA9/MLCUc+GZmKeHANzNLCQe+mVlKOPDNzFLCgW9mlhIOfDOzlHDgm5mlhAPfzCwlHPhmZimhiCh0DV2S9DawrNB19AElwLpCF9FHuFe5cZ9yU6x9+mBEHNTVhr16u5LdsCwijil0EcVOUqP7lBv3KjfuU276Yp88pWNmlhIOfDOzlCjmwL+j0AX0Ee5T7tyr3LhPuelzfSram7ZmZtazivkdvpmZ9SAHvplZShRl4Es6VdIySS9Lqi50PYUk6UeS1kp6IWtsqKR6ScuTfw/M2vb1pG/LJJ1SmKp7n6RDJP2npJckvSjpq8m4e5VF0r6Snpb0XNKnG5Jx96kLkvpLelbSg8l63+5TRBTVF9Af+CMwGtgbeA44vNB1FbAfk4GjgReyxm4GqpPlauCmZPnwpF/7AIcmfexf6NfQS30qBY5OlvcD/pD0w71q3ycBg5PlAcBTwCfcp2779ffAT4EHk/U+3adifId/HPByRPwpIv4/cA8wvcA1FUxEPAZs6DA8HahNlmuBz2SN3xMRWyPiFeBlMv3c40VEc0Q8kyy/DbwEjMS9aicyNiWrA5KvwH3qRNIoYCowJ2u4T/epGAN/JLAia31lMmbvOjgimiETdMDwZNy9AySVAx8l8+7VveogmaZYAqwF6iPCferabcDXgHeyxvp0n4ox8NXFmJ8dzU3qeydpMHAfcEVEvLWzXbsYS0WvImJbRBwFjAKOk3TETnZPZZ8knQGsjYjFuR7SxVjR9akYA38lcEjW+ihgdYFqKVZrJJUCJP+uTcZT3TtJA8iE/d0RcX8y7F51IyI2Ag3AqbhPHX0SmCapicy08omS7qKP96kYA/93wFhJh0raGzgHWFDgmorNAqAqWa4C5meNnyNpH0mHAmOBpwtQX6+TJOBO4KWI+E7WJvcqi6SDJA1JlgcCJwH/jfvUTkR8PSJGRUQ5mQx6NCK+QF/vU6HvGndzZ/x0Mk9Z/BH4RqHrKXAv5gLNQCuZdxFfAoYBjwDLk3+HZu3/jaRvy4DTCl1/L/bpeDI/Qj8PLEm+TnevOvVpIvBs0qcXgOuScfep+55V8O5TOn26T/5oBTOzlCjGKR0zM8sDB76ZWUo48M3MUsKBb2aWEg58M7OUKOY/Ym6WF5K2AUuzhj4TEU0FKses1/ixTEsdSZsiYnAvXm+viGjrreuZdcdTOmYdSCqV9JikJZJekPQ3yfipkp5JPkv+kWRsqKQ6Sc9LelLSxGR8lqQ7JP0K+HHyG673Sfpd8vXJAr5ESylP6VgaDUw+LRLglYj42w7bPw88HBHfltQf+CtJBwH/DkyOiFckDU32vQF4NiI+I+lE4MfAUcm2jwHHR8RmST8FvhsR/yWpDHgYOCxvr9CsCw58S6PNkfm0yO78DvhR8mFsdRGxRFIF8FhkPuuciNj+NwqOBz6bjD0qaZikA5JtCyJic7J8EnB45iN/ANhf0n6R+ex+s17hwDfrICIekzSZzB+/+ImkW4CNdP1xtzv7WNyWrLF+wKSsbwBmvc5z+GYdSPogmc9C/3cyn8B5NLAI+FTySYhkTek8BpyXjFUA66Lrz+H/FXBp1jWOylP5Zt3yO3yzziqAayS1ApuA8yPidUkXAfdL6kfmc9CnALOA/yvpeeAvvPvRuR1dDnw/2W8vMt8oLs7rqzDrwI9lmpmlhKd0zMxSwoFvZpYSDnwzs5Rw4JuZpYQD38wsJRz4ZmYp4cA3M0uJ/wECiCuxXmiSyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 设置模型参数\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softmax',   \n",
    "    'num_class': 3,     \n",
    "    'gamma': 0.1,\n",
    "    'max_depth': 2,\n",
    "    'lambda': 2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 3,\n",
    "    'eta': 0.001,\n",
    "    'seed': 1000,\n",
    "    'nthread': 4,\n",
    "}\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "num_rounds = 200\n",
    "model = xgb.train(params, dtrain, num_rounds)\n",
    "# 对测试集进行预测\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print (\"Accuracy:\", accuracy)\n",
    "# 绘制特征重要性\n",
    "plot_importance(model)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70499893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
